{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 19:13:06.427444: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-19 19:13:06.640929: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-19 19:13:07.550914: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-19 19:13:07.550982: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-19 19:13:07.550992: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "from typing import Tuple\n",
    "\n",
    "import keras\n",
    "import mat73\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nowcasting.unet import res1, res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_expansion(\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        input_window_size: int = 3,\n",
    "        target_window_size: int = 1,\n",
    "        target_offset: int = 1,\n",
    "        step: int = 2,\n",
    "        sample_ratio: int = 1) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    sliding_window_expansion Generates input and target pairs from time series like dataset\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray\n",
    "        Input timeseries array\n",
    "    y : np.ndarray\n",
    "        Target timeseries array\n",
    "    input_window_size : int, optional\n",
    "        Number of timesteps in each input, by default 3\n",
    "    target_window_size : int, optional\n",
    "        Number of timesteps in each target, by default 1\n",
    "    target_offset : int, optional\n",
    "        Number of timesteps the start of each target should be from the end of each input, by default 1\n",
    "    step : int, optional\n",
    "        Number of timesteps to use to determine the start of the next input and target pair, by default 2\n",
    "    sample_ratio : int, optional\n",
    "        Percentage of results to return, by default 1\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[np.ndarray, np.ndarray]\n",
    "        Input and target timeseries pairs\n",
    "    \"\"\"\n",
    "    max_idx = X.shape[\n",
    "        0] - input_window_size - target_window_size - target_offset\n",
    "    x_idx = (np.expand_dims(np.arange(input_window_size), 0) +\n",
    "             np.expand_dims(np.arange(max_idx, step=step), 0).T)\n",
    "    y_idx = (np.expand_dims(np.arange(target_window_size), 0) +\n",
    "             np.expand_dims(np.arange(max_idx, step=step),\n",
    "                            0).T) + input_window_size + target_offset\n",
    "\n",
    "    if sample_ratio < 1:\n",
    "        sample_mask = (np.random.random(size=(len(x_idx))) <= sample_ratio)\n",
    "        x_idx = x_idx[sample_mask]\n",
    "        y_idx = y_idx[sample_mask]\n",
    "\n",
    "    X_new = X[x_idx]\n",
    "    y_new = y[y_idx]\n",
    "\n",
    "    return X_new, y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 2080 Ti, compute capability 7.5\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n",
    "tf.config.optimizer.set_experimental_options({\"layout_optimizer\": False})\n",
    "\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "\n",
    "policy = mixed_precision.Policy(\"mixed_float16\")\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_path = \"../data/full_sample\"\n",
    "mat_files = [f\"{mat_path}/{x}\" for x in os.listdir(mat_path)]\n",
    "mat_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 480/480 [00:06<00:00, 74.54it/s]\n"
     ]
    }
   ],
   "source": [
    "Xs = []\n",
    "ys = []\n",
    "for mat_file in tqdm(mat_files):\n",
    "    mat = scipy.io.loadmat(mat_file)\n",
    "    mat_shape = mat[\"X\"][\"imerg\"][0][0].shape\n",
    "    Xs.append(\n",
    "        np.array([mat[\"X\"][x][0][0]\n",
    "                  for x in [\"imerg\", \"gfs_v\", \"gfs_tpw\"]]).reshape(\n",
    "                      (mat_shape[0], mat_shape[1], 3)))\n",
    "    ys.append(mat[\"X\"][\"gfs_pr\"][0][0].reshape(\n",
    "        (mat_shape[0], mat_shape[1], 1)))\n",
    "\n",
    "Xs = np.array(Xs)\n",
    "ys = np.array(ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 256, 620, 3)\n",
      "(480, 256, 620, 1)\n"
     ]
    }
   ],
   "source": [
    "print(Xs.shape)\n",
    "print(ys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = sliding_window_expansion(Xs,\n",
    "                                ys,\n",
    "                                input_window_size=12,\n",
    "                                target_window_size=8,\n",
    "                                target_offset=0,\n",
    "                                step=8,\n",
    "                                sample_ratio=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_new = []\n",
    "# y_new = []\n",
    "# for i in range(X.shape[0]):\n",
    "#     X_new.append(X[i, :, :, :256, :])\n",
    "#     y_new.append(y[i, :, :, :256, :])\n",
    "\n",
    "# X = np.array(X_new)\n",
    "# y = np.array(y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58, 12, 256, 620, 3)\n",
      "(58, 8, 256, 620, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cutoff = int(X.shape[0] * 0.9)\n",
    "X_train = X[:train_cutoff]\n",
    "y_train = y[:train_cutoff]\n",
    "X_test = X[train_cutoff:]\n",
    "y_test = y[train_cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del Xs, ys, mat\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 19:13:17.960259: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-19 19:13:18.694855: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-11-19 19:13:18.694883: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "2022-11-19 19:13:18.695017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9621 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:04:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 12, 256, 62  0           []                               \n",
      "                                0, 3)]                                                            \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 12, 256, 620  12         ['input_1[0][0]']                \n",
      " alization)                     , 3)                                                              \n",
      "                                                                                                  \n",
      " zero_padding3d (ZeroPadding3D)  (None, 12, 256, 624  0          ['batch_normalization[0][0]']    \n",
      "                                , 3)                                                              \n",
      "                                                                                                  \n",
      " conv_lstm1 (ConvLSTM2D)        (None, 12, 256, 624  3200        ['zero_padding3d[0][0]']         \n",
      "                                , 8)                                                              \n",
      "                                                                                                  \n",
      " conv_lstm13 (ConvLSTM2D)       (None, 12, 256, 624  4640        ['conv_lstm1[0][0]']             \n",
      "                                , 8)                                                              \n",
      "                                                                                                  \n",
      " max_pooling3d (MaxPooling3D)   (None, 12, 128, 312  0           ['conv_lstm13[0][0]']            \n",
      "                                , 8)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 12, 128, 312  32         ['max_pooling3d[0][0]']          \n",
      " rmalization)                   , 8)                                                              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 12, 128, 312  0           ['batch_normalization_1[0][0]']  \n",
      "                                , 8)                                                              \n",
      "                                                                                                  \n",
      " conv_lstm2 (ConvLSTM2D)        (None, 12, 128, 312  13888       ['dropout[0][0]']                \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv_lstm22 (ConvLSTM2D)       (None, 12, 128, 312  18496       ['conv_lstm2[0][0]']             \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv_lstm23 (ConvLSTM2D)       (None, 12, 128, 312  18496       ['conv_lstm22[0][0]']            \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " max_pooling3d_1 (MaxPooling3D)  (None, 12, 64, 156,  0          ['conv_lstm23[0][0]']            \n",
      "                                 16)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 12, 64, 156,  64         ['max_pooling3d_1[0][0]']        \n",
      " rmalization)                    16)                                                              \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 12, 64, 156,  0           ['batch_normalization_2[0][0]']  \n",
      "                                 16)                                                              \n",
      "                                                                                                  \n",
      " conv_lstm3 (ConvLSTM2D)        (None, 12, 64, 156,  55424       ['dropout_1[0][0]']              \n",
      "                                 32)                                                              \n",
      "                                                                                                  \n",
      " conv_lstm32 (ConvLSTM2D)       (None, 12, 64, 156,  73856       ['conv_lstm3[0][0]']             \n",
      "                                 32)                                                              \n",
      "                                                                                                  \n",
      " conv_lstm33 (ConvLSTM2D)       (None, 12, 64, 156,  73856       ['conv_lstm32[0][0]']            \n",
      "                                 32)                                                              \n",
      "                                                                                                  \n",
      " max_pooling3d_2 (MaxPooling3D)  (None, 12, 32, 78,   0          ['conv_lstm33[0][0]']            \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 12, 32, 78,   128        ['max_pooling3d_2[0][0]']        \n",
      " rmalization)                   32)                                                               \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 12, 32, 78,   0           ['batch_normalization_3[0][0]']  \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv_lstm4 (ConvLSTM2D)        (None, 12, 32, 78,   221440      ['dropout_2[0][0]']              \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv_lstm42 (ConvLSTM2D)       (None, 12, 32, 78,   295168      ['conv_lstm4[0][0]']             \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv_lstm43 (ConvLSTM2D)       (None, 12, 32, 78,   295168      ['conv_lstm42[0][0]']            \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 12, 32, 78,   256        ['conv_lstm43[0][0]']            \n",
      " rmalization)                   64)                                                               \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 12, 32, 78,   0           ['batch_normalization_4[0][0]']  \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d (Conv3D)                (None, 11, 32, 78,   4128        ['dropout_3[0][0]']              \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv_lstm5 (ConvLSTM2D)        (None, 11, 32, 78,   8320        ['conv3d[0][0]']                 \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_transpose (Conv3DTransp  (None, 11, 64, 156,  4128       ['conv_lstm5[0][0]']             \n",
      " ose)                            32)                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 11, 64, 156,  0          ['conv_lstm33[0][0]']            \n",
      " ingOpLambda)                    32)                                                              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 11, 64, 156,  0           ['conv3d_transpose[0][0]',       \n",
      "                                 64)                              'tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv_lstm51 (ConvLSTM2D)       (None, 11, 64, 156,  110720      ['concatenate[0][0]']            \n",
      "                                 32)                                                              \n",
      "                                                                                                  \n",
      " conv_lstm52 (ConvLSTM2D)       (None, 11, 64, 156,  73856       ['conv_lstm51[0][0]']            \n",
      "                                 32)                                                              \n",
      "                                                                                                  \n",
      " conv_lstm53 (ConvLSTM2D)       (None, 11, 64, 156,  73856       ['conv_lstm52[0][0]']            \n",
      "                                 32)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 11, 64, 156,  128        ['conv_lstm53[0][0]']            \n",
      " rmalization)                    32)                                                              \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 11, 64, 156,  0           ['batch_normalization_5[0][0]']  \n",
      "                                 32)                                                              \n",
      "                                                                                                  \n",
      " conv3d_1 (Conv3D)              (None, 10, 64, 156,  1040        ['dropout_4[0][0]']              \n",
      "                                 16)                                                              \n",
      "                                                                                                  \n",
      " conv_lstm6 (ConvLSTM2D)        (None, 10, 64, 156,  2112        ['conv3d_1[0][0]']               \n",
      "                                 16)                                                              \n",
      "                                                                                                  \n",
      " conv3d_transpose_1 (Conv3DTran  (None, 10, 128, 312  1040       ['conv_lstm6[0][0]']             \n",
      " spose)                         , 16)                                                             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 10, 128, 312  0          ['conv_lstm23[0][0]']            \n",
      " icingOpLambda)                 , 16)                                                             \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 10, 128, 312  0           ['conv3d_transpose_1[0][0]',     \n",
      "                                , 32)                             'tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv_lstm61 (ConvLSTM2D)       (None, 10, 128, 312  27712       ['concatenate_1[0][0]']          \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv_lstm62 (ConvLSTM2D)       (None, 10, 128, 312  18496       ['conv_lstm61[0][0]']            \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv_lstm63 (ConvLSTM2D)       (None, 10, 128, 312  18496       ['conv_lstm62[0][0]']            \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 10, 128, 312  64         ['conv_lstm63[0][0]']            \n",
      " rmalization)                   , 16)                                                             \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 10, 128, 312  0           ['batch_normalization_6[0][0]']  \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_2 (Conv3D)              (None, 8, 128, 312,  392         ['dropout_5[0][0]']              \n",
      "                                 8)                                                               \n",
      "                                                                                                  \n",
      " conv_lstm7 (ConvLSTM2D)        (None, 8, 128, 312,  544         ['conv3d_2[0][0]']               \n",
      "                                 8)                                                               \n",
      "                                                                                                  \n",
      " conv3d_transpose_2 (Conv3DTran  (None, 8, 256, 624,  264        ['conv_lstm7[0][0]']             \n",
      " spose)                          8)                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2 (Sl  (None, 8, 256, 624,  0          ['conv_lstm13[0][0]']            \n",
      " icingOpLambda)                  8)                                                               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 8, 256, 624,  0           ['conv3d_transpose_2[0][0]',     \n",
      "                                 16)                              'tf.__operators__.getitem_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv_lstm71 (ConvLSTM2D)       (None, 8, 256, 624,  6944        ['concatenate_2[0][0]']          \n",
      "                                 8)                                                               \n",
      "                                                                                                  \n",
      " conv_lstm72 (ConvLSTM2D)       (None, 8, 256, 624,  4640        ['conv_lstm71[0][0]']            \n",
      "                                 8)                                                               \n",
      "                                                                                                  \n",
      " conv_lstm73 (ConvLSTM2D)       (None, 8, 256, 624,  4640        ['conv_lstm72[0][0]']            \n",
      "                                 8)                                                               \n",
      "                                                                                                  \n",
      " conv3d_3 (Conv3D)              (None, 8, 256, 624,  9           ['conv_lstm73[0][0]']            \n",
      "                                 1)                                                               \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 8, 256, 624,  0           ['conv3d_3[0][0]']               \n",
      "                                 1)                                                               \n",
      "                                                                                                  \n",
      " cropping3d (Cropping3D)        (None, 8, 256, 620,  0           ['activation[0][0]']             \n",
      "                                 1)                                                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze (TFOpLamb  (None, 8, 256, 620)  0          ['cropping3d[0][0]']             \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,435,653\n",
      "Trainable params: 1,435,311\n",
      "Non-trainable params: 342\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = res2((12, 256, 620, 3), num_filters_base=8, dropout_rate=0.2)\n",
    "model.summary()\n",
    "# with open(\"modelsummary.txt\", \"w\") as f:\n",
    "#     model.summary(print_fn=lambda x: f.write(x + \"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 19:13:22.203935: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1188495360 exceeds 10% of free system memory.\n",
      "2022-11-19 19:13:23.614442: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1188495360 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 19:14:07.756606: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8600\n",
      "2022-11-19 19:14:08.640605: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-19 19:14:09.360494: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:288] gpu_async_0 cuMemAllocAsync failed to allocate 67895296 bytes: CUDA error: out of memory (CUDA_ERROR_OUT_OF_MEMORY)\n",
      " Reported by CUDA: Free memory/Total memory: 41877504/11552227328\n",
      "2022-11-19 19:14:09.360551: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:293] Stats: Limit:                     10089332736\n",
      "InUse:                     10517751812\n",
      "MaxInUse:                  10517751812\n",
      "NumAllocs:                       13706\n",
      "MaxAllocSize:               1188495360\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-11-19 19:14:09.360894: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:56] Histogram of current allocation: (allocation_size_in_bytes, nb_allocation_of_that_sizes), ...;\n",
      "2022-11-19 19:14:09.360909: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1, 8\n",
      "2022-11-19 19:14:09.360917: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 2, 166\n",
      "2022-11-19 19:14:09.360924: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 4, 69\n",
      "2022-11-19 19:14:09.360931: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 8, 14\n",
      "2022-11-19 19:14:09.360938: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 12, 10\n",
      "2022-11-19 19:14:09.360945: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 16, 131\n",
      "2022-11-19 19:14:09.360951: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 32, 140\n",
      "2022-11-19 19:14:09.360958: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 64, 24\n",
      "2022-11-19 19:14:09.360965: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 128, 114\n",
      "2022-11-19 19:14:09.360971: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 256, 38\n",
      "2022-11-19 19:14:09.360978: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 432, 48\n",
      "2022-11-19 19:14:09.360985: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 512, 109\n",
      "2022-11-19 19:14:09.360991: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 768, 1\n",
      "2022-11-19 19:14:09.360998: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1024, 23\n",
      "2022-11-19 19:14:09.361005: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1028, 1\n",
      "2022-11-19 19:14:09.361011: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1152, 304\n",
      "2022-11-19 19:14:09.361018: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1536, 3\n",
      "2022-11-19 19:14:09.361024: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 2048, 91\n",
      "2022-11-19 19:14:09.361031: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 2304, 80\n",
      "2022-11-19 19:14:09.361038: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 3456, 4\n",
      "2022-11-19 19:14:09.361044: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 4096, 14\n",
      "2022-11-19 19:14:09.361051: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 4608, 440\n",
      "2022-11-19 19:14:09.361057: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 8192, 2\n",
      "2022-11-19 19:14:09.361064: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 9216, 120\n",
      "2022-11-19 19:14:09.361070: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 16384, 14\n",
      "2022-11-19 19:14:09.361077: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 18432, 468\n",
      "2022-11-19 19:14:09.361083: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 36864, 132\n",
      "2022-11-19 19:14:09.361090: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 73728, 248\n",
      "2022-11-19 19:14:09.361096: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 147456, 40\n",
      "2022-11-19 19:14:09.361103: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 294912, 8\n",
      "2022-11-19 19:14:09.361109: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 319488, 66\n",
      "2022-11-19 19:14:09.361116: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 589824, 20\n",
      "2022-11-19 19:14:09.361122: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 638976, 347\n",
      "2022-11-19 19:14:09.361129: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1277952, 879\n",
      "2022-11-19 19:14:09.361135: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 2555904, 817\n",
      "2022-11-19 19:14:09.361142: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 3833856, 24\n",
      "2022-11-19 19:14:09.361151: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 5111808, 480\n",
      "2022-11-19 19:14:09.361157: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 7028736, 2\n",
      "2022-11-19 19:14:09.361164: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 7667712, 2\n",
      "2022-11-19 19:14:09.361171: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 10158080, 2\n",
      "2022-11-19 19:14:09.361177: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 10223616, 207\n",
      "2022-11-19 19:14:09.361184: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 12779520, 2\n",
      "2022-11-19 19:14:09.361190: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 15335424, 5\n",
      "2022-11-19 19:14:09.361197: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 20316160, 1\n",
      "2022-11-19 19:14:09.361203: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 28114944, 4\n",
      "2022-11-19 19:14:09.361210: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 30670848, 3\n",
      "2022-11-19 19:14:09.361216: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 45711360, 1\n",
      "2022-11-19 19:14:09.361223: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 51118080, 4\n",
      "2022-11-19 19:14:09.361229: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 61341696, 1\n",
      "2022-11-19 19:14:09.361236: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 81788928, 1\n",
      "2022-11-19 19:14:09.361242: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 122683392, 1\n",
      "2022-11-19 19:14:09.361249: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 264110080, 1\n",
      "2022-11-19 19:14:09.361255: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1188495360, 1\n",
      "2022-11-19 19:14:09.361462: W tensorflow/core/kernels/gpu_utils.cc:50] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\n",
      "2022-11-19 19:14:09.370753: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:288] gpu_async_0 cuMemAllocAsync failed to allocate 102236160 bytes: CUDA error: out of memory (CUDA_ERROR_OUT_OF_MEMORY)\n",
      " Reported by CUDA: Free memory/Total memory: 8323072/11552227328\n",
      "2022-11-19 19:14:09.370778: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:293] Stats: Limit:                     10089332736\n",
      "InUse:                     10464075748\n",
      "MaxInUse:                  10534529028\n",
      "NumAllocs:                       13712\n",
      "MaxAllocSize:               1188495360\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-11-19 19:14:09.370935: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:56] Histogram of current allocation: (allocation_size_in_bytes, nb_allocation_of_that_sizes), ...;\n",
      "2022-11-19 19:14:09.370946: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1, 8\n",
      "2022-11-19 19:14:09.370953: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 2, 166\n",
      "2022-11-19 19:14:09.370960: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 4, 69\n",
      "2022-11-19 19:14:09.370967: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 8, 14\n",
      "2022-11-19 19:14:09.370973: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 12, 10\n",
      "2022-11-19 19:14:09.370980: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 16, 131\n",
      "2022-11-19 19:14:09.370987: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 32, 139\n",
      "2022-11-19 19:14:09.370993: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 64, 24\n",
      "2022-11-19 19:14:09.371000: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 128, 114\n",
      "2022-11-19 19:14:09.371007: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 256, 38\n",
      "2022-11-19 19:14:09.371013: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 432, 48\n",
      "2022-11-19 19:14:09.371020: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 512, 109\n",
      "2022-11-19 19:14:09.371027: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 768, 1\n",
      "2022-11-19 19:14:09.371034: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1024, 23\n",
      "2022-11-19 19:14:09.371042: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1028, 1\n",
      "2022-11-19 19:14:09.371049: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1152, 304\n",
      "2022-11-19 19:14:09.371056: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1536, 3\n",
      "2022-11-19 19:14:09.371063: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 2048, 90\n",
      "2022-11-19 19:14:09.371069: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 2304, 80\n",
      "2022-11-19 19:14:09.371076: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 3456, 4\n",
      "2022-11-19 19:14:09.371083: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 4096, 14\n",
      "2022-11-19 19:14:09.371089: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 4608, 440\n",
      "2022-11-19 19:14:09.371096: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 8192, 2\n",
      "2022-11-19 19:14:09.371102: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 9216, 120\n",
      "2022-11-19 19:14:09.371109: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 16384, 14\n",
      "2022-11-19 19:14:09.371116: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 18432, 468\n",
      "2022-11-19 19:14:09.371122: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 36864, 132\n",
      "2022-11-19 19:14:09.371129: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 73728, 248\n",
      "2022-11-19 19:14:09.371135: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 147456, 40\n",
      "2022-11-19 19:14:09.371142: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 294912, 8\n",
      "2022-11-19 19:14:09.371148: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 319488, 66\n",
      "2022-11-19 19:14:09.371155: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 589824, 20\n",
      "2022-11-19 19:14:09.371161: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 638976, 351\n",
      "2022-11-19 19:14:09.371168: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1277952, 875\n",
      "2022-11-19 19:14:09.371174: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 2555904, 817\n",
      "2022-11-19 19:14:09.371181: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 3833856, 24\n",
      "2022-11-19 19:14:09.371187: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 5111808, 480\n",
      "2022-11-19 19:14:09.371194: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 7028736, 2\n",
      "2022-11-19 19:14:09.371200: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 7667712, 2\n",
      "2022-11-19 19:14:09.371207: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 10158080, 2\n",
      "2022-11-19 19:14:09.371214: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 10223616, 207\n",
      "2022-11-19 19:14:09.371220: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 12779520, 2\n",
      "2022-11-19 19:14:09.371227: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 15335424, 5\n",
      "2022-11-19 19:14:09.371233: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 20316160, 1\n",
      "2022-11-19 19:14:09.371240: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 28114944, 4\n",
      "2022-11-19 19:14:09.371246: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 30670848, 3\n",
      "2022-11-19 19:14:09.371253: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 45711360, 1\n",
      "2022-11-19 19:14:09.371260: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 51118080, 3\n",
      "2022-11-19 19:14:09.371266: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 61341696, 1\n",
      "2022-11-19 19:14:09.371273: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 81788928, 1\n",
      "2022-11-19 19:14:09.371279: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 122683392, 1\n",
      "2022-11-19 19:14:09.371286: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 264110080, 1\n",
      "2022-11-19 19:14:09.371293: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1188495360, 1\n",
      "2022-11-19 19:14:09.371313: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at concat_op.cc:158 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[4,10,128,312,32] and type half on /job:localhost/replica:0/task:0/device:GPU:0 by allocator gpu_async_0\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/concatenate_1/concat' defined at (most recent call last):\n    File \"/home/pygmy_lord/anaconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/pygmy_lord/anaconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/traitlets/config/application.py\", line 982, in launch_instance\n      app.start()\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/pygmy_lord/anaconda3/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/pygmy_lord/anaconda3/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/pygmy_lord/anaconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_cell\n      result = self._run_cell(\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3139, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3318, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_60306/41008903.py\", line 18, in <module>\n      results = model.fit(X_train,\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/engine/functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/engine/functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/layers/merging/base_merge.py\", line 196, in call\n      return self._merge_function(inputs)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/layers/merging/concatenate.py\", line 134, in _merge_function\n      return backend.concatenate(inputs, axis=self.axis)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/backend.py\", line 3572, in concatenate\n      return tf.concat([to_dense(x) for x in tensors], axis)\nNode: 'model/concatenate_1/concat'\nOOM when allocating tensor with shape[4,10,128,312,32] and type half on /job:localhost/replica:0/task:0/device:GPU:0 by allocator gpu_async_0\n\t [[{{node model/concatenate_1/concat}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_54052]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 18\u001b[0m\n\u001b[1;32m      8\u001b[0m callbacks \u001b[39m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     EarlyStopping(patience\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[1;32m     10\u001b[0m     ReduceLROnPlateau(factor\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, min_lr\u001b[39m=\u001b[39m\u001b[39m0.00001\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m                     save_weights_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m ]\n\u001b[1;32m     17\u001b[0m \u001b[39m#%%\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train,\n\u001b[1;32m     19\u001b[0m                     y_train,\n\u001b[1;32m     20\u001b[0m                     batch_size\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m,\n\u001b[1;32m     21\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[1;32m     22\u001b[0m                     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m     23\u001b[0m                     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     24\u001b[0m                     validation_data\u001b[39m=\u001b[39;49m(X_test, y_test))\n",
      "File \u001b[0;32m~/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/repos/Nowcasting/.venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/concatenate_1/concat' defined at (most recent call last):\n    File \"/home/pygmy_lord/anaconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/pygmy_lord/anaconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/traitlets/config/application.py\", line 982, in launch_instance\n      app.start()\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/pygmy_lord/anaconda3/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/pygmy_lord/anaconda3/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/pygmy_lord/anaconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_cell\n      result = self._run_cell(\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3139, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3318, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_60306/41008903.py\", line 18, in <module>\n      results = model.fit(X_train,\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/engine/functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/engine/functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/layers/merging/base_merge.py\", line 196, in call\n      return self._merge_function(inputs)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/layers/merging/concatenate.py\", line 134, in _merge_function\n      return backend.concatenate(inputs, axis=self.axis)\n    File \"/home/pygmy_lord/repos/Nowcasting/.venv/lib/python3.9/site-packages/keras/backend.py\", line 3572, in concatenate\n      return tf.concat([to_dense(x) for x in tensors], axis)\nNode: 'model/concatenate_1/concat'\nOOM when allocating tensor with shape[4,10,128,312,32] and type half on /job:localhost/replica:0/task:0/device:GPU:0 by allocator gpu_async_0\n\t [[{{node model/concatenate_1/concat}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_54052]"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "model.compile(loss=\"mean_absolute_error\",\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=[\"mae\", \"mse\"])\n",
    "#mean_absolute_error\n",
    "checkpoint_filepath = \"script_n1.h5\"\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=10, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                    verbose=1,\n",
    "                    save_best_only=True,\n",
    "                    save_weights_only=True)\n",
    "]\n",
    "\n",
    "#%%\n",
    "results = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    batch_size=2,\n",
    "                    epochs=50,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(10, 50))\n",
    "\n",
    "# ax.imshow(np.abs(y_hat[0, 0, :, :] - y_test[0, 1, :, :]))\n",
    "ax.imshow(y_test[0, 0, :, :, :])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(10, 50))\n",
    "\n",
    "# ax.imshow(np.abs(y_hat[0, 0, :, :] - y_test[0, 1, :, :]))\n",
    "ax.imshow(y_hat[0, 0, :, :])\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab48bb00c4e609ad4126cd0d5032fb463cf982a4178eca92395db2bbdfbf1f7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
